
# ğŸ“Š Data Science and Statistics Lab

A hands-on lab that covers fundamentals of data science, statistics, and machine learning using Python and Jupyter Notebooks. This repository contains practical exercises for data manipulation, exploratory data analysis, visualization, and common machine learning algorithms.

> NOTE: Add your notebooks and datasets to the repo (for example, a `notebooks/` and `data/` directory) so each practical can link to its implementation.

---


## ğŸ’¡Overview
This lab helps learners build practical skills in:
- Data acquisition, cleaning, and manipulation
- Exploratory data analysis (EDA) and visualization
- Core statistical measures and concepts
- Implementing and evaluating common supervised learning models

Each practical is intended to be a short, self-contained notebook that demonstrates concepts with a dataset and includes exercises.

---

## ğŸ› ï¸Technologies
Primary libraries used:
- ğŸ¼pandas â€” data manipulation and analysis  
- ğŸ”¢NumPy â€” numerical computing  
- ğŸ“ŠMatplotlib & Seaborn â€” data visualization  
- ğŸ¤–scikit-learn â€” machine learning algorithms  
- ğŸ“˜Jupyter Notebook / JupyterLab â€” interactive notebooks

---

## Prerequisites
- Python 3.8+ 
- pip (or conda) for package management

Recommended minimal environment:
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn
- jupyterlab or notebook


## ğŸ§©Practicals (Lab list)
Each practical should ideally have a corresponding notebook named with a leading number (e.g., `01-data-acquisition.ipynb`). Below is the organized list with short descriptions:

1. Data Acquisition using pandas  
   - Importing CSV/Excel/JSON, basic inspection, and reading large files in chunks.

2. Measures of Central Tendency (Mean, Median, Mode)  
   - Calculating and interpreting central tendency and basic summaries.

3. Basics of DataFrame  
   - Structure, indexing, selection, slicing, merging, grouping, and transformations.

4. Missing Values Treatment  
   - Detecting missing data, imputations, and best practices.

5. Creation of Arrays using NumPy  
   - Array creation, vectorized operations, broadcasting, and performance notes.

6. Data Visualization  
   - Plotting with Matplotlib and Seaborn: line, bar, histogram, boxplot, pairplot.

7. Simple Linear Regression  
   - Model building, assumptions, evaluation metrics (MSE, RÂ²), and visualization.

8. Logistic Regression  
   - Binary classification, probability interpretation, performance metrics (accuracy, precision, recall, ROC).

9. K-Nearest Neighbors (KNN)  
   - Instance-based learning, choosing K, standardization, and evaluation.

10. Support Vector Machine (SVM)  
    - Margin maximization, kernels, and hyperparameter tuning.

11. Decision Tree (DT)  
    - Tree building, overfitting, pruning, and feature importance.

12. Random Forest (RF)  
    - Ensemble learning, bagging, out-of-bag error, and feature importance.

Tip: Link each numbered item to its notebook once notebooks are added (e.g., `[01 - Data Acquisition](notebooks/01-data-acquisition.ipynb)`).

---
## ğŸ¯Learning Outcome
By completing this lab, we will gain the ability to handle and preprocess real-world datasets, perform statistical analysis to extract meaningful insights, and visualize data trends and patterns effectively. They will also learn to build and evaluate machine learning models while developing a strong understanding of core machine learning concepts and algorithms. Each notebook is self-contained, demonstrating concepts with datasets and hands-on exercises to reinforce learning.

---


