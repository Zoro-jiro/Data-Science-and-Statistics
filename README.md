
# Data Science and Statistics Lab

A hands-on lab that covers fundamentals of data science, statistics, and machine learning using Python and Jupyter Notebooks. This repository contains practical exercises for data manipulation, exploratory data analysis, visualization, and common machine learning algorithms.

> NOTE: Add your notebooks and datasets to the repo (for example, a `notebooks/` and `data/` directory) so each practical can link to its implementation.

---

## Table of contents
- [Overview](#overview)
- [Technologies](#technologies)
- [Prerequisites](#prerequisites)
- [Practicals (Lab list)](#practicals-lab-list)
---

## Overview
This lab helps learners build practical skills in:
- Data acquisition, cleaning, and manipulation
- Exploratory data analysis (EDA) and visualization
- Core statistical measures and concepts
- Implementing and evaluating common supervised learning models

Each practical is intended to be a short, self-contained notebook that demonstrates concepts with a dataset and includes exercises.

---

## Technologies
Primary libraries used:
- pandas — data manipulation and analysis  
- NumPy — numerical computing  
- Matplotlib & Seaborn — data visualization  
- scikit-learn — machine learning algorithms  
- Jupyter Notebook / JupyterLab — interactive notebooks

---

## Prerequisites
- Python 3.8+ 
- pip (or conda) for package management

Recommended minimal environment:
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn
- jupyterlab or notebook


## Practicals (Lab list)
Each practical should ideally have a corresponding notebook named with a leading number (e.g., `01-data-acquisition.ipynb`). Below is the organized list with short descriptions:

1. Data Acquisition using pandas  
   - Importing CSV/Excel/JSON, basic inspection, and reading large files in chunks.

2. Measures of Central Tendency (Mean, Median, Mode)  
   - Calculating and interpreting central tendency and basic summaries.

3. Basics of DataFrame  
   - Structure, indexing, selection, slicing, merging, grouping, and transformations.

4. Missing Values Treatment  
   - Detecting missing data, imputations, and best practices.

5. Creation of Arrays using NumPy  
   - Array creation, vectorized operations, broadcasting, and performance notes.

6. Data Visualization  
   - Plotting with Matplotlib and Seaborn: line, bar, histogram, boxplot, pairplot.

7. Simple Linear Regression  
   - Model building, assumptions, evaluation metrics (MSE, R²), and visualization.

8. Logistic Regression  
   - Binary classification, probability interpretation, performance metrics (accuracy, precision, recall, ROC).

9. K-Nearest Neighbors (KNN)  
   - Instance-based learning, choosing K, standardization, and evaluation.

10. Support Vector Machine (SVM)  
    - Margin maximization, kernels, and hyperparameter tuning.

11. Decision Tree (DT)  
    - Tree building, overfitting, pruning, and feature importance.

12. Random Forest (RF)  
    - Ensemble learning, bagging, out-of-bag error, and feature importance.

Tip: Link each numbered item to its notebook once notebooks are added (e.g., `[01 - Data Acquisition](notebooks/01-data-acquisition.ipynb)`).

---


